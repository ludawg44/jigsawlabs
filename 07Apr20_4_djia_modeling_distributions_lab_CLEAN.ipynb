{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of 4-djia-modeling-distributions-lab.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludawg44/jigsawlabs/blob/master/07Apr20_4_djia_modeling_distributions_lab_CLEAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZXQKLM7PPx7",
        "colab_type": "text"
      },
      "source": [
        "# Modeling A Distribution Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGFryEQDPPx8",
        "colab_type": "text"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvQbu6H2PPx9",
        "colab_type": "text"
      },
      "source": [
        "In this lesson, we'll put our knowledge of modeling distributions to see the probability of different daily fluctuations in the stock market.\n",
        "\n",
        "Let's start by loading our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ7OGqZdREwp",
        "colab_type": "code",
        "outputId": "84650acf-037a-452e-9451-437e11b16ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install gcsfs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/18/3b/454be7c97d05e15eb20a0099f425f0ed6b7552e352c77adb923c3872ba14/gcsfs-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.7.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.7.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (46.1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxNdfJukPPx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "url = \"gs://curriculum-assets/mod-2/upload_DJIA_table.csv\"\n",
        "stocks_df = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GYBqiUhPPyB",
        "colab_type": "code",
        "outputId": "37bd01b5-faf9-41fb-a0f0-00e1d23383aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stocks_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvCnnCnXPPyF",
        "colab_type": "text"
      },
      "source": [
        "Make sure that the data is in the correct format, and change it if it isn't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4PeItzOPPyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "date_col = \n",
        "\n",
        "stocks_df = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1BHPaOWPPyJ",
        "colab_type": "text"
      },
      "source": [
        "Let's start by getting a sense of the range of dates in our dataset.  We'd like to get a sense of the range of years, months, and days before using it for our analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvDbxutuPPyJ",
        "colab_type": "text"
      },
      "source": [
        "Let's start with the year.  Display all of the years listed and the number of rows for each year.\n",
        "\n",
        "> Do so without creating another column in your dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q21ORy1LPPyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write code here\n",
        "\n",
        "# 2015    252\n",
        "# 2014    252\n",
        "# 2013    252\n",
        "# 2011    252\n",
        "# 2010    252\n",
        "# 2009    252\n",
        "# 2012    250\n",
        "# 2016    126\n",
        "# 2008    101\n",
        "# Name: Date, dtype: int64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzNldXglPPyM",
        "colab_type": "text"
      },
      "source": [
        "We can also use group by to make some calculations.  Here we `groupby` the month and then count.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cian_JoUPPyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stocks_df.groupby(lambda idx: stocks_df.iloc[idx]['Date'].month).count()['Date']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9GhAGwPPyO",
        "colab_type": "text"
      },
      "source": [
        "> Notice that groupby take a lambda function.  The argument passed the function is the index of the row, and so we select the row using iloc, then calculate the month value for each row.  Pandas groups by that returned month value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_1hAxDsPPyP",
        "colab_type": "text"
      },
      "source": [
        "Ok, now we've seen that we have daily stock data for the years between 2008 and 2016, where 2008 and 2016 have missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwbS_d12PPyP",
        "colab_type": "text"
      },
      "source": [
        "### Calculating Daily Change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLYFezqLPPyQ",
        "colab_type": "text"
      },
      "source": [
        "Let's take another look at our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRJtBgzvPPyQ",
        "colab_type": "code",
        "outputId": "72a8e47e-0785-4e7f-988b-a40e1965d660",
        "colab": {}
      },
      "source": [
        "stocks_df[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>17924.240234</td>\n",
              "      <td>18002.380859</td>\n",
              "      <td>17916.910156</td>\n",
              "      <td>17949.369141</td>\n",
              "      <td>82160000</td>\n",
              "      <td>17949.369141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>17712.759766</td>\n",
              "      <td>17930.609375</td>\n",
              "      <td>17711.800781</td>\n",
              "      <td>17929.990234</td>\n",
              "      <td>133030000</td>\n",
              "      <td>17929.990234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-29</td>\n",
              "      <td>17456.019531</td>\n",
              "      <td>17704.509766</td>\n",
              "      <td>17456.019531</td>\n",
              "      <td>17694.679688</td>\n",
              "      <td>106380000</td>\n",
              "      <td>17694.679688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date          Open          High           Low         Close  \\\n",
              "0 2016-07-01  17924.240234  18002.380859  17916.910156  17949.369141   \n",
              "1 2016-06-30  17712.759766  17930.609375  17711.800781  17929.990234   \n",
              "2 2016-06-29  17456.019531  17704.509766  17456.019531  17694.679688   \n",
              "\n",
              "      Volume     Adj Close  \n",
              "0   82160000  17949.369141  \n",
              "1  133030000  17929.990234  \n",
              "2  106380000  17694.679688  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al7uGoygPPyT",
        "colab_type": "text"
      },
      "source": [
        "Now we'd like to track the daily fluctuations in the stock market, so add a column that shows difference between the open and close of the stock market, name the column `Movement`.  Assign the new dataframe to the variable `df_with_movement`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AKyraLYPPyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movement = None\n",
        "df_with_movement = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfM-cTNGPPyW",
        "colab_type": "text"
      },
      "source": [
        "Now that we have a plot that shows daily changes in the stock market, let's plot a frequency distribution of our `Movement` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr3YprfQPPyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sacx05PNPPyZ",
        "colab_type": "text"
      },
      "source": [
        "Answer: <img src=\"https://github.com/jigsawlabs-student/modeling-distributions/blob/master/movement-hist.png?raw=1\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM0-usLzPPya",
        "colab_type": "text"
      },
      "source": [
        "Next let's plot probability density function of the daily fluctuation in prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGWONMx3PPya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAMgDVPIPPyd",
        "colab_type": "text"
      },
      "source": [
        "Answer: <img src=\"https://github.com/jigsawlabs-student/modeling-distributions/blob/master/movement-density.png?raw=1\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3QgGM6LPPye",
        "colab_type": "text"
      },
      "source": [
        "### Modeling our Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5atFNg8PPye",
        "colab_type": "text"
      },
      "source": [
        "Now let's choose a normal distribution to begin modeling our random variable.  Begin by initializing a random variable with the location and spread values of our distribution above.  Assign it to the variable `norm_dist_djia`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thrI1vsGPPyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "norm_dist_djia = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNfXjWXzPPyh",
        "colab_type": "code",
        "outputId": "ff0e5455-ffbb-40e3-e2c2-5228500ae626",
        "colab": {}
      },
      "source": [
        "norm_dist_djia.mean()\n",
        "# -3.9162063846153483\n",
        "\n",
        "norm_dist_djia.std()\n",
        "# 141.2279379239883"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141.2279379239883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvoUPQXhPPyj",
        "colab_type": "text"
      },
      "source": [
        "Now create a list of 100 values between the one percentile value of the distribution and 99th percentile values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ByTLUxPPyj",
        "colab_type": "text"
      },
      "source": [
        "And pass through these values to the distribution's pdf function, to get a list of pdf values at each of the provided points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UMB70IzPPyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = None\n",
        "pdf_nums_norm = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrlmXeNRPPym",
        "colab_type": "text"
      },
      "source": [
        "Then plot the modeled normal distribution along with a frequency distribution of our sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXiC--q2PPym",
        "colab_type": "code",
        "outputId": "05d94952-c5c3-4879-f173-c736a250a4d4",
        "colab": {}
      },
      "source": [
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "# ax = fig.add_subplot(111)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImmJC624PPyp",
        "colab_type": "text"
      },
      "source": [
        "Answer: <img src=\"https://github.com/jigsawlabs-student/modeling-distributions/blob/master/djia-normal.png?raw=1\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAyKYsoSPPyq",
        "colab_type": "text"
      },
      "source": [
        "Let's see the probability, according to our modeled distribution, of getting lower than -750 in a day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAK4yCjnPPyq",
        "colab_type": "code",
        "outputId": "ff9ff50a-a4fd-49fc-8b8c-e24d38e802ea",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "p_less_than_750 = None\n",
        "\n",
        "np.format_float_positional(p_less_than_750)\n",
        "# '0.00000006360021876390582'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.00000006360021876390582'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c90v6aKPPyt",
        "colab_type": "text"
      },
      "source": [
        "Let's compare this to our the CDF on our actual data.  Scipy provides us with the ECDF object, which allows us to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWOGOPZrPPyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from statsmodels.distributions.empirical_distribution import ECDF\n",
        "e_movement = ECDF(movement_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNHKi5cCPPyv",
        "colab_type": "code",
        "outputId": "bcca9c7f-d265-40f6-e17d-b59c59ee34c9",
        "colab": {}
      },
      "source": [
        "e_movement(-750)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001005530417295123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZLUthOvPPyx",
        "colab_type": "text"
      },
      "source": [
        "We can see that this is a very big difference (in statistical terms) than what our normal distribution modeled above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih_A5TQAPPyy",
        "colab_type": "text"
      },
      "source": [
        "### Changing our Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phWY5DRGPPyy",
        "colab_type": "text"
      },
      "source": [
        "Let's try a skewed t distribution instead of modeling with a normal distribution.  We'll set the t-distribution with 2 degrees of freedom, but you can experiment with different values for this.  We'll keep the mean and scale the same as with our normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAvgeulTPPyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import t\n",
        "import numpy as np\n",
        "t_dist = t(df=2, loc=movement_col.mean(), scale=movement_col.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972Bt6dcPPy2",
        "colab_type": "text"
      },
      "source": [
        "Then we proceed with defining a range of x values, and finding the corresponding array of pdf values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxILQCG6PPy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x = np.linspace(t_dist.ppf(0.0001), t_dist.ppf(0.9999), 100)\n",
        "y_1 = t_dist.pdf(x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQQbYNHyPPy4",
        "colab_type": "text"
      },
      "source": [
        "Then we plot our distributions to see how they line up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10KEUyQ9PPy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig_1 = plt.figure()\n",
        "ax_1 = fig_1.add_subplot(111)\n",
        "ax_1.plot(x, pdf_nums_norm,\n",
        "'r-', alpha=0.6, label='norm pdf')\n",
        "# plot of t distribution\n",
        "ax_1.plot(x,y_1)\n",
        "\n",
        "# plot of histogram\n",
        "ax_1.hist(movement_col, density = True, alpha = .5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahed5pSiPPy7",
        "colab_type": "text"
      },
      "source": [
        "> The t distribution (in orange) puts more weights on the tails of the distribution than the normal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf0hSqsDPPy7",
        "colab_type": "text"
      },
      "source": [
        "Now let's look at the probabilituy of a fluctuation less than -750."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q82QnagkPPy7",
        "colab_type": "code",
        "outputId": "50b3e66d-968e-4619-ad66-75c44a2b9b49",
        "colab": {}
      },
      "source": [
        "t_less_than_750 = t.cdf(-750)\n",
        "\n",
        "np.format_float_positional(t_less_than_750)\n",
        "\n",
        "# '0.017006983460026732'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.017006983460026732'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nJi05LcPPy-",
        "colab_type": "code",
        "outputId": "2f44701a-a0d3-46af-d37d-8fd847c0a2df",
        "colab": {}
      },
      "source": [
        "e_movement(-750)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001005530417295123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb-PmGoPPPzA",
        "colab_type": "text"
      },
      "source": [
        "### Resources\n",
        "\n",
        "As an alternative to our aggregated dataset, [also see the UCI dataset](http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index) for daily prices of individual stocks."
      ]
    }
  ]
}